{"cells":[{"cell_type":"code","source":["!pip install onnx\n","!pip install onnxsim"],"metadata":{"id":"8KJdwjyKXP_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FK-snb6Cq4tI","executionInfo":{"status":"ok","timestamp":1719385060085,"user_tz":-540,"elapsed":263,"user":{"displayName":"Tomohiko Mukai","userId":"16569110691282235802"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","import torch.utils as utils\n","from torchvision import datasets, transforms\n","from PIL import Image\n","from io import BytesIO\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"XSxs2dYKr1DZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"DEf3sD5Uq4tJ","executionInfo":{"status":"ok","timestamp":1719385063197,"user_tz":-540,"elapsed":243,"user":{"displayName":"Tomohiko Mukai","userId":"16569110691282235802"}}},"outputs":[],"source":["im2tensor = transforms.ToTensor()\n","\n","def imfile2tensor(filename):\n","    img = Image.open(filename)\n","    alpha = Image.fromarray(np.zeros(img.size), mode='L')\n","    img.putalpha(alpha) # Unity RenderTextureの構造に一致させる\n","    tensor = im2tensor(img)\n","    return tensor"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nOYM7Vz-q4tJ","executionInfo":{"status":"ok","timestamp":1719385051125,"user_tz":-540,"elapsed":254,"user":{"displayName":"Tomohiko Mukai","userId":"16569110691282235802"}}},"outputs":[],"source":["class UnityDataset(torch.utils.data.Dataset):\n","    def __init__(self, begin, end, transform = None):\n","        self.transform = transform\n","        # images\n","        image_title = '/content/drive/MyDrive/Sentis/Image'\n","        self.data = list()\n","        for i in range(begin, end):\n","            image_name = image_title + str(i).zfill(4) + '.png'\n","            tensor = imfile2tensor(image_name)\n","            self.data.append(tensor)\n","        # labels\n","        label_name = '/content/drive/MyDrive/Sentis/Visibility.csv'\n","        with open(label_name) as label_file:\n","            labels = label_file.readlines()\n","        self.label = []\n","        for i in range(begin, end):\n","            l = int(labels[i].split('\\n')[0])\n","            self.label.append(torch.FloatTensor([l]))\n","        self.num_items = len(self.label)\n","\n","    def __len__(self):\n","        return self.num_items\n","\n","    def __getitem__(self, idx):\n","        out_data = self.data[idx]\n","        out_label = self.label[idx]\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","        return out_data, out_label"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KFIA8IkYq4tJ","executionInfo":{"status":"ok","timestamp":1719385431719,"user_tz":-540,"elapsed":352052,"user":{"displayName":"Tomohiko Mukai","userId":"16569110691282235802"}}},"outputs":[],"source":["# 1000個中900個を訓練データ\n","trainset = UnityDataset(0, 900)\n","# 残り100個をテストデータに\n","testset = UnityDataset(900, 1000)\n","dataloader = torch.utils.data.DataLoader(\n","    trainset,\n","    batch_size = 100,\n","    shuffle = True)"]},{"cell_type":"code","source":["class Detector(nn.Module):\n","    def __init__(self, im_size, in_channels, num_hiddens):\n","        super(Detector, self).__init__()\n","        # プーリング層を介して2つの畳み込み層を設定\n","        self.conv1 = nn.Conv2d(\n","            in_channels=in_channels,\n","            out_channels=num_hiddens//2,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1)\n","        self.pool1 = nn.MaxPool2d(\n","            kernel_size=3,\n","            stride=3)\n","        self.conv2 = nn.Conv2d(\n","            in_channels=num_hiddens//2,\n","            out_channels=num_hiddens,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1)\n","        # 全結合層への入力次元数を計算\n","        nfeatures = np.floor((im_size - 1) / 3.0 + 1)   #conv1\n","        nfeatures = np.floor((nfeatures - 3) / 3.0 + 1) #pool1\n","        nfeatures = int(nfeatures) * 3\n","        nfeatures = num_hiddens * nfeatures * nfeatures\n","        # 全結合層2つを通じて出力\n","        self.linear1 = nn.Linear(nfeatures, nfeatures // 2)\n","        self.linear2 = nn.Linear(nfeatures // 2, 1)\n","\n","    def forward(self, inputs):\n","        z = inputs[:, 0:3, :, :] # remove alpha channel\n","        z = self.conv1(z)\n","        z = F.relu(z)\n","        z = self.pool1(z)\n","        z = self.conv2(z)\n","        z = torch.flatten(z, 1)\n","        z = self.linear1(z)\n","        z = F.relu(z)\n","        z = self.linear2(z)\n","        return F.sigmoid(z) # nn.BCELossを用いるためsigmoidを利用"],"metadata":{"id":"YmrDjLjBXCfW","executionInfo":{"status":"ok","timestamp":1719385471977,"user_tz":-540,"elapsed":435,"user":{"displayName":"Tomohiko Mukai","userId":"16569110691282235802"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = Detector(64, 3, 6).to(device)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=1.0e-3)"],"metadata":{"id":"PtULYAmFXEEr","executionInfo":{"status":"ok","timestamp":1719385478411,"user_tz":-540,"elapsed":309,"user":{"displayName":"Tomohiko Mukai","userId":"16569110691282235802"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model.train()\n","num_epochs = 50\n","loss_list = []\n","for i in range(num_epochs):\n","    losses = []\n","    for x, label in dataloader:\n","        model.zero_grad()\n","        x = x.to(device)\n","        y = model(x)\n","        loss = criterion(y, label)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.cpu().detach().numpy())\n","    loss_list.append(np.average(losses))\n","    print(\"EPOCH: {} loss: {}\".format(i, np.average(losses)))\n","\n","torch.save(model.state_dict(), 'sentis_weights.pth')"],"metadata":{"id":"QAUisxAUXGGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# テスト\n","\n","testloader = torch.utils.data.DataLoader(\n","    testset,\n","    batch_size = 100,\n","    shuffle = True)\n","\n","def discretize(y):\n","    return 1.0 if y[0] >= 0.5 else 0.0\n","\n","model.eval()\n","num_total = 0\n","num_oks = 0\n","with torch.no_grad():\n","    for x, t in testloader:\n","        x = x.to(device)\n","        y = model(x)\n","        for iy, it in zip(y, t):\n","            if discretize(iy) == it[0]:\n","                num_oks += 1\n","            num_total += 1\n","    print(num_oks / num_total)"],"metadata":{"id":"TqOLSAEBXJkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import onnx\n","import onnxsim\n","\n","# 出力するモデルの設定\n","model = Detector(\n","    im_size=64,\n","    in_channels=3,\n","    num_hiddens=6).to(device)\n","checkpoint = torch.load('sentis_weights.pth')\n","model.load_state_dict(checkpoint)\n","\n","# onnxファイルへの出力\n","onnx_file = 'sentis.onnx'\n","torch.onnx.export(\n","    model=model,\n","    args=torch.randn((1, 4, 64, 64)), # 入力値ダミー\n","    f='sentis.onnx', # モデル名\n","    opset_version=15, # Sentis1.3ではopsetバージョンは15に設定\n","    export_params=True, # 必ずTrue\n","    do_constant_folding=True, # True/Falseどちらでもよい（はず）\n","    input_names=['inputs'],  # 入力テンソルは1つ\n","    output_names=['output'], # 出力テンソルも1つ\n",")\n","\n","# 型の推定\n","#model_onnx1 = onnx.load(onnx_file)\n","#model_onnx1 = onnx.shape_inference.infer_shapes(model_onnx1)\n","#onnx.save(model_onnx1, onnx_file)\n","\n","# モデル構造の最適化\n","#model_onnx2 = onnx.load(onnx_file)\n","#model_simp, check = onnxsim.simplify(model_onnx2)\n","#onnx.save(model_simp, onnx_file)"],"metadata":{"id":"ejDOrqYTXMJg"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}